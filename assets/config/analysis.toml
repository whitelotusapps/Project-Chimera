[analysis_variables]
# PATH TO PERSONAL IDIOLECT FILE
idiolect_file_path = "C:\\temp\\code\\Project Chimera\\assets\\idiolect\\my_words.txt"

# PATH WHERE TO STORE PERSONAL IDIOLECT FILE
generated_from_corpus_idiotlect_output_path = "C:\\temp\\code\\Project Chimera\\assets\\idiolect"

# PATH TO THE JSON FILES GENERATED BY THE TRANSCRIPTION SCRIPT
# STATED ANOTHER WAY: THE JSON FILES GENERATED BY FASTER WHISPER\
# THIS MAY BE THE JSON FOLDER WITHIN THE PATH DEFINED BY THE
# search_and_replace_transcription_output_path VARIABLE WITHIN THE
# transcription.toml FILE
analysis_directories_to_process = [
    "C:\\temp\\Transcriptions\\search_and_replaced\\JSON",
]

# WHERE ARE THE ORIGINAL FULL SOURCE AUDIO FILES LOCATED?
# THIS IS USED FOR GENERATING CHUNK METADATA
# THIS MAY BE THE SAME LOCATION AS THE audio_file_directories_to_process VARIABLE
# IN THE transcription.toml FILE
analysis_source_audio_file_directory = "C:\\temp\\Audio Files"

# FOLDERS TO IGNORE
analysis_directories_to_ignore = ["C:\\temp\\Audio Files\\original"]

# THE FOLDER WHERE THE FINAL ANALYSIS JSON FILE WILL BE OUTPUT
analysis_output_directory = "C:\\temp\\Transcriptions\\analysis"

# THIS IS THE PATH TO A CUSTOM LABEL FILE
# THIS IS UED BY THE KNOWLEGATOR MODELS
analysis_label_file_path = "C:\\temp\\code\\Project Chimera\\assets\\categories\\large_v4.txt"

# THIS IS THE PATH TO A CUSTOM QUESTIONS CSV FILE
# THIS IS UED BY THE KNOWLEGATOR MODELS
analysis_questions_file_path = "C:\\temp\\code\\Project Chimera\\assets\\questions\\questions_v4.csv"

######################################################################################################################

[[analysis_variables.model_configs]]
use_model = "yes"
model_name = "ml6team/keyphrase-extraction-kbir-inspec"
model_type = "keyphrase-extraction"
model_host = "local"

[[analysis_variables.model_configs]]
use_model = "yes"
model_name = "boltuix/bert-emotion"
model_type = "sequence_classification"
model_host = "local"

# # THIS MODEL WORKS REALLY WELL FOR EMOTIONAL CLASSIFICATION (2024-08-10)
[[analysis_variables.model_configs]]
use_model = "yes"
model_name = "SamLowe/roberta-base-go_emotions"
model_type = "sequence_classification"
model_host = "local"

# THIS IS THE Q&A MODEL THAT WORKS **THE BEST** OUT OF ALL OF THE Q&A MODELS I HAVE TRIED
# THIS MODEL IS ALSO EXCELLENT AT NER IDENTIFICATION PER CUSTOM LABELS
# FILES LIKE: gliclass_ner.txt, large_v4.txt
[[analysis_variables.model_configs]]
use_model = "yes"
model_name = "knowledgator/gliner-multitask-large-v0.5"
model_type = "gliner"
enable_qna = "yes"
enable_custom_labels = "no"
model_host = "local"

# THE BELOW MODELS WERE MY "STANDARD" (2024-07-29)
[[analysis_variables.model_configs]]
use_model = "yes"
model_name = "newsmediabias/UnBIAS-Named-Entity-Recognition"
model_type = "token_classification"
model_host = "local"

[[analysis_variables.model_configs]]
use_model = "yes"
model_name = "KoalaAI/Text-Moderation"
model_type = "sequence_classification"
model_host = "local"

[[analysis_variables.model_configs]]
use_model = "yes"
model_name = "duanyu027/moderation_0628"
model_type = "sequence_classification"
model_host = "local"

[[analysis_variables.model_configs]]
use_model = "yes"
model_name = "en_core_web_sm"
model_type = "spacy"
model_host = "local"

[[analysis_variables.model_configs]]
use_model = "no"
model_name = "stanford_corenlp"
model_type = "corenlp"
model_host = "server"
server_address = "http://10.100.100.23"
server_port = "9000"
# THE BELOW ANNOTATOR SET RUNS FINE ON 4GB OF RAM FOR THE VM
annotators = "tokenize,docdate,ssplit,pos,lemma,ner,entitymentions,depparse,parse,sentiment,regexner"
# THE BELOW ANNOTATOR SET REQUIRES AT LEAST 8GB OF RAM FOR THE VM
# annotators = "tokenize, docdate, ssplit, truecase, pos, lemma, ner, regexner, entitylink, parse, depparse, coref, kbp, relation, openie, sentiment"
pipelineLanguage = "en"
outputFormat = "json"
ner_additional_tokensregex_rules_file = "ner_additional_tokensregex_rules.txt"

[analysis_variables.contractions_dict]
"ain't" = "am not"
"aren't" = "are not"
"can't" = "cannot"
"can't've" = "cannot have"
"'cause" = "because"
"could've" = "could have"
"couldn't" = "could not"
"couldn't've" = "could not have"
"didn't" = "did not"
"doesn't" = "does not"
"don't" = "do not"
"hadn't" = "had not"
"hadn't've" = "had not have"
"hasn't" = "has not"
"haven't" = "have not"
"he'd" = "he would"
"he'd've" = "he would have"
"he'll" = "he will"
"he'll've" = "he will have"
"he's" = "he is"
"how'd" = "how did"
"how'd'y" = "how do you"
"how'll" = "how will"
"how's" = "how is"
"I'd" = "I would"
"I'd've" = "I would have"
"I'll" = "I will"
"I'll've" = "I will have"
"I'm" = "I am"
"I've" = "I have"
"isn't" = "is not"
"it'd" = "it would"
"it'd've" = "it would have"
"it'll" = "it will"
"it'll've" = "it will have"
"it's" = "it is"
"let's" = "let us"
"ma'am" = "madam"
"mayn't" = "may not"
"might've" = "might have"
"mightn't" = "might not"
"mightn't've" = "might not have"
"must've" = "must have"
"mustn't" = "must not"
"mustn't've" = "must not have"
"needn't" = "need not"
"needn't've" = "need not have"
"o'clock" = "of the clock"
"oughtn't" = "ought not"
"oughtn't've" = "ought not have"
"shan't" = "shall not"
"sha'n't" = "shall not"
"shan't've" = "shall not have"
"she'd" = "she would"
"she'd've" = "she would have"
"she'll" = "she will"
"she'll've" = "she will have"
"she's" = "she is"
"should've" = "should have"
"shouldn't" = "should not"
"shouldn't've" = "should not have"
"so've" = "so have"
"so's" = "so is"
"that'd" = "that would"
"that'd've" = "that would have"
"that's" = "that is"
"there'd" = "there would"
"there'd've" = "there would have"
"there's" = "there is"
"they'd" = "they would"
"they'd've" = "they would have"
"they'll" = "they will"
"they'll've" = "they will have"
"they're" = "they are"
"they've" = "they have"
"to've" = "to have"
"wasn't" = "was not"
"we'd" = "we would"
"we'd've" = "we would have"
"we'll" = "we will"
"we'll've" = "we will have"
"we're" = "we are"
"we've" = "we have"
"weren't" = "were not"
"what'll" = "what will"
"what'll've" = "what will have"
"what're" = "what are"
"what's" = "what is"
"what've" = "what have"
"when's" = "when is"
"when've" = "when have"
"where'd" = "where did"
"where's" = "where is"
"where've" = "where have"
"who'll" = "who will"
"who'll've" = "who will have"
"who's" = "who is"
"who've" = "who have"
"why's" = "why is"
"why've" = "why have"
"will've" = "will have"
"won't" = "will not"
"won't've" = "will not have"
"would've" = "would have"
"wouldn't" = "would not"
"wouldn't've" = "would not have"
"y'all" = "you all"
"y'all'd" = "you all would"
"y'all'd've" = "you all would have"
"y'all're" = "you all are"
"y'all've" = "you all have"
"you'd" = "you would"
"you'd've" = "you would have"
"you'll" = "you will"
"you'll've" = "you will have"
"you're" = "you are"
"you've" = "you have"

# SET THE BELOW TO THE NATAL INFORMATION FOR THE
# INDIVIDUAL BEING ANALYZED
[analysis_variables.astrology_variables]
planet_and_aspect_orb = 2.0
natal_date_and_time_of_birth = "1980-01-01T00:00:00"
natal_lat = "38n058'56''"
natal_long = "094w40'14''"
natal_timezone = "America/Chicago"
swiss_eph_path = "C:\\temp\\code\\Project Chimera\\assets\\astrology\\eph"
immanuel_house_system = "WHOLE_SIGN"

# THE BELOW TWO FILES ARE TAB SEPARATED VALUE FILES
# ONE IS FOR THE PART OF SPIRIT
# ONE IS FOR THE PART OF FORTUNE
# THESE ARE ZODIACAL RELEASING DATA FILES
pos_file = "ZACK_POS_2025_07_13.tsv"
pof_file = "ZACK_POF_2025_07_13.tsv"
